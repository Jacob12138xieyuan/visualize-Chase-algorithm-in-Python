{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Minimal Covers</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devise and implement three Python functions that compute a minimal cover, all accessible (by the algorithm given in the lecture) minimal covers, and all possible minimal covers of a given list of functional dependencies, respectively. \n",
    "Complete the provided Jupyter Notebook using the Python 3 kernel. \n",
    "Do not change the name and the parameters of the functions in the template. \n",
    "You may add ancillary functions if necessary or convenient.\n",
    "You may import additional Python standard libraries but no external libraries.\n",
    "\n",
    "For all questions, use the following data structures.\n",
    "A functional dependency is represented as a list of two lists. For\n",
    "example, the functional dependency {A, B} â†’ {C} is represented as [['A', 'B'], ['C']]. \n",
    "A set of functional dependencies is represented as a list of functional dependencies. \n",
    "\n",
    "Ensure that your functions process the input and produce the output in the format specified in the corresponding questions.\n",
    "\n",
    "For simplicity, you may assume that the input is always valid (e.g. no empty string, no incomplete functional dependency).\n",
    "Consider the case in which a functional dependency's left- or right-hand side is empty.\n",
    "\n",
    "The code should be readable and adequately commented.\n",
    "\n",
    "The marking team considers clarity of the code and comments, quality of the algorithm and  implementation, and correctness and efficiency of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicate your student number: A0290880X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnr7px4Fw_8S"
   },
   "source": [
    "# Question 1 (4 points)\n",
    "Write a function *min_cover* that takes a list of functional dependencies as input and returns a minimal cover of the functional dependencies, for example,\n",
    "````\n",
    "min_cover([[['A'], ['B', 'C']],[['B'], ['C','D']], [['D'], ['B']], [['A','B','E'], ['F']]])\n",
    "outputs: [[['A'], ['B']], [['B'], ['C']], [['B'], ['D']], [['D'], ['B']], [['A', 'E'], ['F']]]\n",
    "````\n",
    "The results is a minimal cover, i.e. a list of functional dependencies.\n",
    "There might be more than one correct answer to this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C', 'D', 'E', 'F']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_attributes(fds: list[list]):\n",
    "    \"\"\"\n",
    "    Generate all attributes from 'A'\n",
    "    \"\"\"\n",
    "    max_char = ''\n",
    "    for fd in fds:\n",
    "        lhs, rhs = fd\n",
    "        for char in ''.join(lhs + rhs):\n",
    "            if char > max_char:\n",
    "                max_char = char\n",
    "    # found max_char. e.g. F\n",
    "    return [chr(char_code) for char_code in range(ord('A'), ord(max_char) + 1)]\n",
    "\n",
    "fds = [[['A'], ['B', 'C']],[['B'], ['C','D']], [['D'], ['B']], [['A','B','E'], ['F']]]\n",
    "get_all_attributes(fds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "snpcm0cf0BPl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B', 'C', 'D'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cal_attribute_closure(attributes: set, fds: list[list]):\n",
    "    \"\"\"\n",
    "    It is a fix point algorithm\n",
    "    attribute: set of attribute like {'A', 'E'}\n",
    "    fds: a list of fd\n",
    "    \"\"\"\n",
    "    closure = attributes.copy()\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for lhs, rhs in fds:\n",
    "            if set(lhs).issubset(closure) and not set(rhs).issubset(closure):\n",
    "                # union\n",
    "                closure.update(rhs)\n",
    "                changed = True\n",
    "    return closure\n",
    "\n",
    "fds = [[['A'], ['B', 'C']], [['B'], ['C','D']], [['D'], ['B']], [['A','B','E'], ['F']]]\n",
    "attributes = {'A'}\n",
    "cal_attribute_closure(attributes, fds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('A', 'E')],\n",
       " OrderedDict([(('A',), {'A', 'B', 'C', 'D'}),\n",
       "              (('B',), {'B', 'C', 'D'}),\n",
       "              (('C',), {'C'}),\n",
       "              (('D',), {'B', 'C', 'D'}),\n",
       "              (('E',), {'E'}),\n",
       "              (('F',), {'F'}),\n",
       "              (('A', 'B'), {'A', 'B', 'C', 'D'}),\n",
       "              (('A', 'C'), {'A', 'B', 'C', 'D'}),\n",
       "              (('A', 'D'), {'A', 'B', 'C', 'D'}),\n",
       "              (('A', 'E'), {'A', 'B', 'C', 'D', 'E', 'F'})]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from collections import OrderedDict\n",
    "\n",
    "def cal_combination_attribute_closure(all_attributes: list, fds: list[list]):\n",
    "    \"\"\"\n",
    "    Generate combinations of attributes untill superkey is found\n",
    "    \"\"\"\n",
    "    combs = OrderedDict()\n",
    "    superkeys = []\n",
    "    for i in range(len(all_attributes) - 1):\n",
    "        found_superkey = False\n",
    "        for combination in combinations(all_attributes, i + 1):\n",
    "            comb = combination\n",
    "            attribute_closure = cal_attribute_closure(set(comb), fds)\n",
    "            combs[tuple(sorted(comb))] = attribute_closure\n",
    "            # check if comb is superkey\n",
    "            if attribute_closure == set(all_attributes):\n",
    "                superkeys.append(comb)\n",
    "                found_superkey = True\n",
    "                break\n",
    "        if found_superkey: break\n",
    "    return superkeys, combs\n",
    "\n",
    "fds = [[['A'], ['B', 'C']], [['B'], ['C','D']], [['D'], ['B']], [['A','B','E'], ['F']]]\n",
    "attributes = get_all_attributes(fds)\n",
    "cal_combination_attribute_closure(attributes, fds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_redundant(fd, fds):\n",
    "    \"\"\"\n",
    "    Check if fd can be derived from other fds\n",
    "    :param fd: the fd we need to check\n",
    "    :param fds: other fds except fd\n",
    "    :return: bool\n",
    "    \"\"\"\n",
    "    remaining_fds = fds.copy()\n",
    "    # remove fd from fds first\n",
    "    remaining_fds.remove(fd)\n",
    "    X, Y = fd\n",
    "    closure = cal_attribute_closure(set(X), remaining_fds)\n",
    "    # after apply other fds, wether we find X->Y, which is Y in closure of X \n",
    "    return set(Y).issubset(closure)\n",
    "\n",
    "fd = [['A'], ['C']]\n",
    "fds = [[['B'], ['C']], [['A'], ['C']], [['A'], ['B']], [['B'], ['D']], [['D'], ['B']], [['A', 'E'], ['F']]]\n",
    "is_redundant(fd, fds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['A'], ['B']], [['B'], ['A']], [['B'], ['C']], [['A'], ['C']]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_duplicate_fds(fds):\n",
    "    \"\"\"\n",
    "    Remove duplicate fds in fds and maintain the order\n",
    "    :param fds: a list of functional dependencies\n",
    "    :return: new list of functional dependencies without duplicate\n",
    "    \"\"\"\n",
    "    seen = set()\n",
    "    new_fds = []\n",
    "    for fd in fds:\n",
    "        str_item = str(fd)  # Convert inner lists to strings for set comparison\n",
    "        if str_item not in seen:\n",
    "            seen.add(str_item)\n",
    "            new_fds.append(fd)\n",
    "    return new_fds\n",
    "\n",
    "fds = [[['A'], ['B']], [['B'], ['A']], [['B'], ['C']], [['A'], ['C']], [['A'], ['C']]]\n",
    "remove_duplicate_fds(fds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_cover(fds):\n",
    "    print(f\"Original dependencies: \\n{fds}\")\n",
    "    all_attributes = get_all_attributes(fds)\n",
    "\n",
    "    # Step 1: Decompose the right-hand side (RHS) of each dependency\n",
    "    fds1 = []\n",
    "    for fd in fds:\n",
    "        lhs, rhs = fd\n",
    "        for rhs_attribute in rhs:\n",
    "            fds1.append([lhs, [rhs_attribute]])\n",
    "    print(f\"After minimize RHS: \\n{fds1}\")\n",
    "\n",
    "    # Step 2: Minimize the left-hand side (LHS) of each dependency\n",
    "    # Calculate attribute closure\n",
    "    _, attribute_closures = cal_combination_attribute_closure(all_attributes, fds1)\n",
    "    fds2 = []\n",
    "    for fd in fds1:\n",
    "        lhs, rhs = fd\n",
    "        # remove trivial dependency, e.g. A,B->A\n",
    "        if set(rhs).issubset(set(lhs)):\n",
    "            continue\n",
    "        # lhs is already minimized\n",
    "        if len(lhs) == 1:\n",
    "            fds2.append(fd)\n",
    "        # lhs is not minimized\n",
    "        else:\n",
    "            # find first attribute closure which contains rhs\n",
    "            for attributes_set, closure in attribute_closures.items():\n",
    "                # e.g. 'F' should not be in attributes_set, this is trivial\n",
    "                if set(rhs).issubset(closure) and (not set(rhs).issubset(attributes_set)):\n",
    "                    fds2.append([sorted(list(attributes_set)), rhs])\n",
    "                    break\n",
    "    # remove duplicate fd\n",
    "    fds2 = remove_duplicate_fds(fds2)\n",
    "    print(f\"After minimize LHS: \\n{fds2}\")\n",
    "\n",
    "    # Step 3: Check if each fd is redundant. i.e. fd can be derived from other fds\n",
    "    # Only need to find one solution\n",
    "    min_cover = []\n",
    "    remaining_fds2 = fds2.copy()\n",
    "    for fd in fds2:\n",
    "        if is_redundant(fd, remaining_fds2):\n",
    "            remaining_fds2.remove(fd)\n",
    "        else:\n",
    "            min_cover.append(fd)\n",
    "    print(f\"After remove redundant: \\n{min_cover}\")\n",
    "    return min_cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dependencies: \n",
      "[[['A'], ['B', 'C']], [['B'], ['C', 'D']], [['D'], ['B']], [['A', 'B', 'E'], ['F']]]\n",
      "After minimize RHS: \n",
      "[[['A'], ['B']], [['A'], ['C']], [['B'], ['C']], [['B'], ['D']], [['D'], ['B']], [['A', 'B', 'E'], ['F']]]\n",
      "After minimize LHS: \n",
      "[[['A'], ['B']], [['A'], ['C']], [['B'], ['C']], [['B'], ['D']], [['D'], ['B']], [['A', 'E'], ['F']]]\n",
      "After remove redundant: \n",
      "[[['A'], ['B']], [['B'], ['C']], [['B'], ['D']], [['D'], ['B']], [['A', 'E'], ['F']]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[['A'], ['B']],\n",
       " [['B'], ['C']],\n",
       " [['B'], ['D']],\n",
       " [['D'], ['B']],\n",
       " [['A', 'E'], ['F']]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fds = [[['A'], ['B','C']],[['B'], ['C','D']], [['D'], ['B']], [['A','B','E'], ['F']]]\n",
    "\n",
    "# test case in ppt\n",
    "# fds = [[['B'], ['D']], [['B'], ['C']], [['C'], ['B']], [['C'], ['D']], [['B'], ['E']], [['C'], ['E']]]\n",
    "\n",
    "min_cover(fds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The result you get should be similar to:**\n",
    "```\n",
    "[[['A'], ['B']],\n",
    " [['B'], ['C']],\n",
    " [['B'], ['D']],\n",
    " [['D'], ['B']],\n",
    " [['A', 'E'], ['F']]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l01R13KyznwG"
   },
   "source": [
    "# Question 2 (3 points) \n",
    "Write a function *min_covers* that takes a list of functional dependencies as input and returns all minimal covers reachable from the given list of functional dependencies, for example,\n",
    "````\n",
    "min_cover([[['A'], ['A', 'B']], [['B'], ['A','C']], [['A'], ['C']], [['A','B'], ['C']]])\n",
    "outputs: [\n",
    "            [[['A'], ['B']], [['B'], ['A']], [['B'], ['C']]],\n",
    "            [[['A'], ['B']], [['B'], ['A']], [['A'], ['C']]]\n",
    "        ]\n",
    "````\n",
    "The results is a list of minimal covers.\n",
    "Make sure that you clearly explain the rationale of your solution in comments of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_min_covers(fds: list[list]) -> list[list]:\n",
    "    \"\"\"\n",
    "    To minimize fds itself (remove redundant in all possible ways)\n",
    "    :param fds: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    all_min_covers = []\n",
    "\n",
    "    def backtrack(cur_min_cover, remaining_fds, index):\n",
    "        if index == len(remaining_fds):\n",
    "            # remaining fds cannot contain redundant\n",
    "            no_redundant_fd = True\n",
    "            for fd in remaining_fds:\n",
    "                if is_redundant(fd, remaining_fds):\n",
    "                    no_redundant_fd = False\n",
    "                    break\n",
    "            if no_redundant_fd: all_min_covers.append(cur_min_cover)\n",
    "            return\n",
    "        \n",
    "        cur_fd = remaining_fds[index]\n",
    "        if is_redundant(cur_fd, remaining_fds):\n",
    "            # don't select cur_min_cover\n",
    "            backtrack(cur_min_cover, remaining_fds[:index] + remaining_fds[index+1:], index)\n",
    "        # select cur_min_cover\n",
    "        backtrack(cur_min_cover+[cur_fd], remaining_fds, index+1)\n",
    "        \n",
    "    backtrack([], fds, 0)\n",
    "    return all_min_covers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "S9jFQwUT0B2m"
   },
   "outputs": [],
   "source": [
    "def min_covers(fds):\n",
    "    print(f\"Original dependencies: \\n{fds}\")\n",
    "    all_attributes = get_all_attributes(fds)\n",
    "\n",
    "    # Step 1: Decompose the right-hand side (RHS) of each dependency\n",
    "    fds1 = []\n",
    "    for fd in fds:\n",
    "        lhs, rhs = fd\n",
    "        for rhs_attribute in rhs:\n",
    "            fds1.append([lhs, [rhs_attribute]])\n",
    "    print(f\"After minimize RHS: \\n{fds1}\")\n",
    "\n",
    "    # Step 2: Minimize the left-hand side (LHS) of each dependency\n",
    "    # Calculate attribute closure\n",
    "    _, attribute_closures = cal_combination_attribute_closure(all_attributes, fds1)\n",
    "    fds2 = []\n",
    "    for fd in fds1:\n",
    "        lhs, rhs = fd\n",
    "        # remove trivial dependency, e.g. A,B->A\n",
    "        if set(rhs).issubset(set(lhs)):\n",
    "            continue\n",
    "        # lhs is already minimized\n",
    "        if len(lhs) == 1:\n",
    "            fds2.append(fd)\n",
    "        # lhs is not minimized\n",
    "        else:\n",
    "            # find first attribute closure which contains rhs\n",
    "            for attributes_set, closure in attribute_closures.items():\n",
    "                # e.g. 'F' should not be in attributes_set, this is trivial\n",
    "                if set(rhs).issubset(closure) and (not set(rhs).issubset(attributes_set)):\n",
    "                    fds2.append([sorted(list(attributes_set)), rhs])\n",
    "                    break\n",
    "    # remove duplicate fd\n",
    "    fds2 = remove_duplicate_fds(fds2)\n",
    "    print(f\"After minimize LHS: \\n{fds2}\")\n",
    "\n",
    "    # Step 3: Check if fd is redundant. i.e. can be derived from other fds\n",
    "    min_covers = generate_all_min_covers(fds2)        \n",
    "    print(f\"After remove redundant, multiple possible min_covers: \\n{min_covers}\")\n",
    "    return min_covers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dependencies: \n",
      "[[['A'], ['A', 'B']], [['B'], ['A', 'C']], [['A'], ['C']], [['A', 'B'], ['C']]]\n",
      "After minimize RHS: \n",
      "[[['A'], ['A']], [['A'], ['B']], [['B'], ['A']], [['B'], ['C']], [['A'], ['C']], [['A', 'B'], ['C']]]\n",
      "After minimize LHS: \n",
      "[[['A'], ['B']], [['B'], ['A']], [['B'], ['C']], [['A'], ['C']]]\n",
      "After remove redundant, multiple possible min_covers: \n",
      "[[[['A'], ['B']], [['B'], ['A']], [['A'], ['C']]], [[['A'], ['B']], [['B'], ['A']], [['B'], ['C']]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[['A'], ['B']], [['B'], ['A']], [['A'], ['C']]],\n",
       " [[['A'], ['B']], [['B'], ['A']], [['B'], ['C']]]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fds = [[['A'], ['A', 'B']], [['B'], ['A','C']], [['A'], ['C']], [['A','B'], ['C']]]\n",
    "\n",
    "# test case in ppt\n",
    "# fds = [[['B'], ['D']], [['B'], ['C']], [['C'], ['B']], [['C'], ['D']], [['B'], ['E']], [['C'], ['E']]]\n",
    "\n",
    "min_covers(fds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The result you get should be similar to:**\n",
    "```\n",
    "[\n",
    "    [[['A'], ['B']], [['B'], ['A']], [['B'], ['C']]],\n",
    "    [[['A'], ['B']], [['B'], ['A']], [['A'], ['C']]]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oBHb-1zzxT_"
   },
   "source": [
    "# Question 3 (3 points)\n",
    "* Write a function *all_min_covers* that takes a list of functional dependencies as input and returns all minimal covers, for example,\n",
    "````\n",
    "all_min_covers([[['A'], ['B']],[['B'], ['C']], [['C'], ['A']]])\n",
    "outputs: [\n",
    "\t[[['A'], ['C']], [['B'], ['A']], [['C'], ['A']], [['A'], ['B']]],\n",
    "\t[[['B'], ['C']], [['C'], ['A']], [['A'], ['B']]],\n",
    "\t[[['C'], ['B']], [['A'], ['C']], [['C'], ['A']], [['B'], ['C']]],\n",
    "\t[[['C'], ['B']], [['A'], ['C']], [['B'], ['A']]],\n",
    "\t[[['B'], ['C']], [['A'], ['B']], [['B'], ['A']], [['C'], ['B']]]\n",
    "]\n",
    "````\n",
    "\n",
    "The results is a list of minimal covers.\n",
    "Make sure that you clearly explain the rationale of your solution in comments of the code.\n",
    "This question is challenging and not everyone may find a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['A'], ['B']],\n",
       " [['A'], ['C']],\n",
       " [['B'], ['C']],\n",
       " [['B'], ['A']],\n",
       " [['C'], ['A']],\n",
       " [['C'], ['B']]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_all_reachable_pairs(fds):\n",
    "    \"\"\"\n",
    "    Use dfs to get each node's all reachable node\n",
    "    :param fds: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    graph = {}\n",
    "    reachable_pairs = []\n",
    "\n",
    "    # Build the graph\n",
    "    for fd in fds:\n",
    "        X, Y = fd\n",
    "        if X[0] not in graph:\n",
    "            graph[X[0]] = set()\n",
    "        graph[X[0]].add(Y[0])\n",
    "\n",
    "    # Perform DFS\n",
    "    def dfs(visited, start_node, current_node):\n",
    "        visited.add(start_node)\n",
    "        for neighbor in graph.get(current_node, []):\n",
    "            if neighbor not in visited:\n",
    "                reachable_pairs.append([[start_node], [neighbor]])\n",
    "                dfs(visited, start_node, neighbor)\n",
    "\n",
    "    for node in graph.keys():\n",
    "        # generate pairs where A can reach\n",
    "        visited = set()\n",
    "        dfs(visited, node, node)\n",
    "\n",
    "    return reachable_pairs\n",
    "\n",
    "fds = [[['A'], ['B']],[['B'], ['C']], [['C'], ['A']]]\n",
    "generate_all_reachable_pairs(fds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8wziQnpaztbu"
   },
   "outputs": [],
   "source": [
    "def all_min_covers(fds):\n",
    "    # graph dfs, start from A, can reach B,C; start from B, can reach A,C; start from C, can reach A,B\n",
    "    # we have [[['A'],['B']], [['A'],['C']], [['B'],['C']], [['B'],['A']], [['C'],['A']], [['C'],['B']]]\n",
    "    # generate its min covers\n",
    "    fds1 = generate_all_reachable_pairs(fds)\n",
    "    all_min_covers = min_covers(fds1)\n",
    "    return all_min_covers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dependencies: \n",
      "[[['A'], ['B']], [['A'], ['C']], [['B'], ['C']], [['B'], ['A']], [['C'], ['A']], [['C'], ['B']]]\n",
      "After minimize RHS: \n",
      "[[['A'], ['B']], [['A'], ['C']], [['B'], ['C']], [['B'], ['A']], [['C'], ['A']], [['C'], ['B']]]\n",
      "After minimize LHS: \n",
      "[[['A'], ['B']], [['A'], ['C']], [['B'], ['C']], [['B'], ['A']], [['C'], ['A']], [['C'], ['B']]]\n",
      "After remove redundant, multiple possible min_covers: \n",
      "[[[['A'], ['C']], [['B'], ['A']], [['C'], ['B']]], [[['A'], ['C']], [['B'], ['C']], [['C'], ['A']], [['C'], ['B']]], [[['A'], ['B']], [['B'], ['C']], [['C'], ['A']]], [[['A'], ['B']], [['B'], ['C']], [['B'], ['A']], [['C'], ['B']]], [[['A'], ['B']], [['A'], ['C']], [['B'], ['A']], [['C'], ['A']]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[['A'], ['C']], [['B'], ['A']], [['C'], ['B']]],\n",
       " [[['A'], ['C']], [['B'], ['C']], [['C'], ['A']], [['C'], ['B']]],\n",
       " [[['A'], ['B']], [['B'], ['C']], [['C'], ['A']]],\n",
       " [[['A'], ['B']], [['B'], ['C']], [['B'], ['A']], [['C'], ['B']]],\n",
       " [[['A'], ['B']], [['A'], ['C']], [['B'], ['A']], [['C'], ['A']]]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fds = [[['A'], ['B']],[['B'], ['C']], [['C'], ['A']]]\n",
    "all_min_covers(fds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The result you get should be:**\n",
    "```\n",
    "[\n",
    "\t[[['A'], ['C']], [['B'], ['A']], [['C'], ['A']], [['A'], ['B']]],\n",
    "\t[[['B'], ['C']], [['C'], ['A']], [['A'], ['B']]],\n",
    "\t[[['C'], ['B']], [['A'], ['C']], [['C'], ['A']], [['B'], ['C']]],\n",
    "\t[[['C'], ['B']], [['A'], ['C']], [['B'], ['A']]],\n",
    "\t[[['B'], ['C']], [['A'], ['B']], [['B'], ['A']], [['C'], ['B']]]\n",
    "]\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
